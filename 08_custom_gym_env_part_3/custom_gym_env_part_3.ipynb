{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d2124f-645c-49fd-9297-4b66967fde48",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating a custom `gym` environment for the Inventory Management problem Part 3: Implementing `reset()`\n",
    "\n",
    "- In `__init__()` we defined the allowed ranges for the problem parameters\n",
    "\n",
    "<img src=\"images/sample/1.png\" width=\"500\"/>\n",
    "\n",
    "- For a particular shop, the values of `daily_mean_demand`, `unit_selling_price` and `daily_holding_cost_per_unit` is constant.\n",
    "\n",
    "| Shop Number | Product | $\\lambda$ | `unit_selling_price` | `unit_buying_price` | `daily_holding_cost_per_unit` |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| 1 | Bananas | 50 | 5 | 2 | 0.5 |\n",
    "| 2 | Wine | 30 | 15 | 7 | 0.25 |\n",
    "| ... | ... | ... | ... | ... | ... |\n",
    "\n",
    "- Each episode simulates a different shop with different parameters. The parameters stay constant during an episode.\n",
    "\n",
    "| Episode Number | $\\lambda$ | `unit_selling_price` | `unit_buying_price` | `daily_holding_cost_per_unit` |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 1 | 50 | 5 | 2 | 0.5 |\n",
    "| 2 | 30 | 15 | 7 | 0.25 |\n",
    "| ... | ... | ... | ... | ... |\n",
    "\n",
    "- Goal: train a policy that works for a wide variety of shops with different parameters.\n",
    "\n",
    "- `reset()` needs to initialize an episode $\\implies$ fix the problem parameters by sampling from the parameter space.\n",
    "\n",
    "<img src=\"images/sample/2.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82472759-3422-4d4b-84d6-6415c85915d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.spaces import Box\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "\n",
    "\n",
    "class InventoryEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Must define self.observation_space and self.action_space here\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define action space: bounds, space type, shape\n",
    "        \n",
    "        # Bound: Shelf space is limited\n",
    "        self.max_capacity = 4000\n",
    "        \n",
    "        # Space type: Better to use Box than Discrete, since Discrete will lead to too many output nodes in the NN\n",
    "        # Shape: rllib cannot handle scalar actions, so turn it into a numpy array with shape (1,)\n",
    "        self.action_space = Box(low=np.array([0]), high=np.array([self.max_capacity]))\n",
    "        \n",
    "        # Define observation space: bounds, space type, shape\n",
    "        \n",
    "        # Shape: The lead time controls the shape of observation space\n",
    "        self.lead_time = 5\n",
    "        self.obs_dim = self.lead_time + 4\n",
    "        \n",
    "        # Bounds: Define high of the remaining observation space elements\n",
    "        self.max_mean_daily_demand = 200\n",
    "        self.max_unit_selling_price = 100\n",
    "        self.max_daily_holding_cost_per_unit = 5\n",
    "        \n",
    "        obs_low = np.zeros((self.obs_dim,))\n",
    "        obs_high = np.array([self.max_capacity for _ in range(self.lead_time)] +\n",
    "                            [self.max_mean_daily_demand, self.max_unit_selling_price,\n",
    "                             self.max_unit_selling_price, self.max_daily_holding_cost_per_unit\n",
    "                             ]\n",
    "                            )\n",
    "        self.observation_space = Box(low=obs_low, high=obs_high)\n",
    "        \n",
    "        # The random number generator that will be used throughout the environment\n",
    "        self.rng = default_rng()\n",
    "        \n",
    "        # All instance variables are defined in the __init__() method\n",
    "        self.current_obs = None\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Returns: the observation of the initial state\n",
    "        Reset the environment to initial state so that a new episode (independent of previous ones) may start\n",
    "        \"\"\"\n",
    "        \n",
    "        # Sample parameter values from the parameter space\n",
    "        \n",
    "        # Set mean daily demand (lambda)\n",
    "        mean_daily_demand = self.rng.uniform() * self.max_mean_daily_demand\n",
    "        \n",
    "        # Set selling price\n",
    "        selling_price = self.rng.uniform() * self.max_unit_selling_price\n",
    "            \n",
    "        # Set buying price: buying price cannot be higher than selling price\n",
    "        buying_price = self.rng.uniform() * selling_price\n",
    "        \n",
    "        # Set daily holding cose per unit: holding cost cannot be higher than buying_price\n",
    "        daily_holding_cost_per_unit = self.rng.uniform() * min(buying_price, self.max_daily_holding_cost_per_unit)\n",
    "        \n",
    "        # Return the first observation\n",
    "        self.current_obs = np.array([0 for _ in range(self.lead_time)] + \n",
    "                                    [mean_daily_demand, selling_price, buying_price, daily_holding_cost_per_unit]\n",
    "                                    )\n",
    "        return self.current_obs\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Returns: the next observation, the reward, done and optionally additional info\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        \"\"\"\n",
    "        Returns: None\n",
    "        Show the current environment state e.g. the graphical window in `CartPole-v1`\n",
    "        This method must be implemented, but it is OK to have an empty implementation if rendering is not\n",
    "        important\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Returns: None\n",
    "        This method is optional. Used to cleanup all resources (threads, graphical windows) etc.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def seed(self, seed=None):\n",
    "        \"\"\"\n",
    "        Returns: List of seeds\n",
    "        This method is optional. Used to set seeds for the environment's random number generator for \n",
    "        obtaining deterministic behavior\n",
    "        \"\"\"\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e10d37-51cd-4aaa-8e92-5ceb99c5e4aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "| Observation/Action | Sample | `gym Space` |\n",
    "| --- | --- | --- |\n",
    "| (Array of) floating point numbers | `[ 1.2, 3.4, 4.1, 0.9]` | `Box` |\n",
    "| Integer | 1 | `Discrete` |\n",
    "| Array of integers | `[2, 1]` | `MultiDiscrete` |\n",
    "\n",
    "- [Documentation of all `gym` `Space`s](https://www.gymlibrary.dev/api/spaces/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee105890-32cc-4c35-aa74-246a2c1e80a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
