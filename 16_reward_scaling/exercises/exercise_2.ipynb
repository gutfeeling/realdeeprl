{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18b1b0e1-6351-472b-8a90-2f763d8f950f",
   "metadata": {},
   "source": [
    "# Modify `MyScaleReward` so that it accounts for the goodwill penalty\n",
    "\n",
    "In the video lesson, we defined our custom reward scaling wrapper `MyScaleReward`. I have included the code below. \n",
    "\n",
    "The hard inventory management environment has a slightly different reward function. It includes a term for goodwill penalty.\n",
    "\n",
    "Your job is to edit the `MyScaleReward` wrapper so that it takes the goodwill penalty into account. For this, you would need to re-estimate the average low scale. \n",
    "\n",
    "You are free to make your own reasoned assumptions about the average values of the various quantities like `goodwill_penalty_per_unit` and unmet demand. Since this is an estimation problem, there's no exactly right answer. The trick is to balance simplicity \n",
    "and correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fdfaf8a-64ec-493e-a4bd-b2f8edf85026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Edit the following wrapper so that it takes goodwill penalty into account\n",
    "class MyScaleReward(gym.RewardWrapper):\n",
    "    def reward(self, reward):\n",
    "        avg_unit_selling_price = self.env.max_unit_selling_price / 2\n",
    "        avg_num_items_bought_per_day = avg_num_items_sold_per_day = self.env.max_mean_daily_demand / 2\n",
    "        avg_unit_buying_price = self.env.max_unit_selling_price / 4\n",
    "        avg_daily_holding_cost_per_unit = self.env.max_daily_holding_cost_per_unit / 2\n",
    "        avg_num_items_held_per_day = self.env.max_mean_daily_demand / 2\n",
    "        avg_high_scale = avg_unit_selling_price * avg_num_items_sold_per_day\n",
    "        avg_low_scale = - (avg_unit_buying_price * avg_num_items_bought_per_day +\n",
    "                           avg_daily_holding_cost_per_unit * avg_num_items_held_per_day\n",
    "                           )\n",
    "        mid = (avg_high_scale + avg_low_scale) / 2\n",
    "        linearly_mapped_reward = 2 * (reward - mid) / (avg_high_scale - avg_low_scale)\n",
    "        return np.arctan(linearly_mapped_reward) / np.arctan(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
